---
title: "cwb-cads functionality"
date: "July 24, 2024"
author: Philipp Heinrich
editor: source
format:
  html:
    toc: true
    toc-float: true
    collapsed: false
    smooth-scroll: false
    number-sections: true
    df-print: paged
---

# Setup

```{r, message = FALSE}
rm(list = ls())
library(tidyverse)
library(httr2)
library(jsonlite)
library(ggrepel)
url_api <- "http://127.0.0.1:5000"
```

- get API access token via `/user/login`
```{r, message = FALSE}
access.token <- str_interp("${url_api}/user/login") |> 
  request() |> 
  req_method("POST") |> 
  req_body_form(password = 'mmda-admin', username = 'admin') |> 
  req_perform() |>
  magrittr::extract2("body") |>
  rawToChar() |> fromJSON() |>
  magrittr::extract2("access_token")
```

# Corpora

- corpus access via `/corpus/`
```{r}
corpora <- str_interp("${url_api}/corpus/") |> 
  request() |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |>
  rawToChar() |> fromJSON() |> 
  tibble()

corpora
```

- we use `"SZ-2018-2022"` as an example here
```{r}
corpus.id <- corpora |>
  filter(cwb_id == "SZ-2018-2022") |> 
  pull(id)

corpus <- str_interp("${url_api}/corpus/${corpus.id}") |> 
  request() |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() 
```

## Meta Data

- indexed structural (and positional) attributes can be accessed directly at `/corpus/<id>/`
```{r}
corpus |> magrittr::extract2("p_atts")

corpus |> magrittr::extract2("s_atts")

corpus |> magrittr::extract2("s_annotations")
```

- `s_annotations` belong to `s_atts` (as long as the corpus was correctly indexed)
- in this context, we refer to the `s_att` as `level` with corresponding `key`s (such that meta data is stored in `level_key`)
- they are not stored in the database by default

```{r}
str_interp("${url_api}/corpus/${corpus.id}/meta/") |> 
  request() |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() 
```

- we can store meta data from annotated s-attributes (`level_key`) using a `PUT` request
- we specify the `value_type` here (use `"unicode"` for categorical data)
```{r}
str_interp("${url_api}/corpus/${corpus.id}/meta/") |> 
  request() |> 
  req_method('PUT') |> 
  req_body_json(list(level = 'text', key = 'year', value_type = 'unicode')) |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()
```

```{r}
str_interp("${url_api}/corpus/${corpus.id}/meta/") |> 
  request() |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> tibble() |> 
  magrittr::extract2("annotations") 
```

- and corresponding frequency counts (only reasonable for categorical data)
```{r}
str_interp("${url_api}/corpus/${corpus.id}/meta/frequencies") |> 
  request() |> 
  req_url_query(level = 'text', key = 'year') |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()
```

- if you try to do this without storing the meta data first, you'll get a `404`
```{r, error = TRUE}
str_interp("${url_api}/corpus/${corpus.id}/meta/frequencies") |> 
  request() |> 
  req_url_query(level = 'text', key = 'month') |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()
```

## Subcorpora

- we create subcorpora for each year in `"SZ-2018-2022"`
- we need `level`, `key`, the corresponding `values_unicode`, and the `name` of the subcorpus
```{r}
for (y in 2018:2022){
  subcorpus <- str_interp("${url_api}/corpus/${corpus.id}/subcorpus/") |> 
    request() |> 
    req_method('PUT') |> 
    req_body_json(data = list(level = 'text', key = 'year', values_unicode = list(paste0("y", as.character(y))), name = as.character(y))) |> 
    req_auth_bearer_token(access.token) |> 
    req_perform() |> 
    magrittr::extract2("body") |> rawToChar() |> fromJSON()
}
```

```{r}
subcorpora <- str_interp("${url_api}/corpus/${corpus.id}/subcorpus/") |> 
  request() |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

subcorpora
```

# Keyword Analysis

- keyword analyses are comparisons between two frequency lists ("target" and "reference")
- a frequency list can either be compiled from a whole corpus or a subcorpus
- two types of keyword analysis are supported:
  + (sub-)corpus 1 vs. (sub-)corpus 2
  + subcorpus vs. rest of the corpus
- mode is detected automatically
  + i.e. providing a subcorpus as the target and its original corpus as the reference will automatically switch to subcorpus vs. rest (if not suppressed)

## Example: SZ-2018-2022 vs. FAZ-2020-2022

```{r}
corpus.id <- corpora |> filter(cwb_id == "SZ-2018-2022") |> pull(id)
corpus.id.reference <- corpora |> filter(cwb_id == "FAZ-2020-2022") |> pull(id)
```

### Creation

- different positional attributes can be compared to one another (`p` and `p_reference`)
  + default: `lemma` (fallback if not given in corpus: `word`)
```{r}
kw.id <- request(str_interp("${url_api}/keyword/")) |> 
  req_body_json(list(corpus_id = corpus.id,
                     corpus_id_reference = corpus.id.reference)) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("id")
```

### Keyword Table

- the result of a keyword analysis is a frequency comparison table of individual `items` with corresponding association measures (`scores`)
```{r}
kw.table.page <- request(str_interp("${url_api}/keyword/${kw.id}/items")) |>
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

kw.table.page |> 
  magrittr::extract2("items") |> 
  magrittr::extract2("scores") |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = kw.table.page |> magrittr::extract2("items") |> magrittr::extract2("item"))
```

- by default, the top `page_size=10` items according to `sort_by="conservative_log_ratio"` are given
- user should be able to switch between different association measures and paginate through results
```{r}
kw.table.page <- request(str_interp("${url_api}/keyword/${kw.id}/items")) |>
  req_url_query(sort_by = "log_likelihood", page_size = 20, page_number = 2) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

kw.table.page |> 
  magrittr::extract2("items") |> 
  magrittr::extract2("scores") |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = kw.table.page |> magrittr::extract2("items") |> magrittr::extract2("item"))
```

## Example: SZ-2020 vs. SZ-2019
```{r}
subcorpus.id <- subcorpora |> filter(name == "2020") |> pull(id)
subcorpus.id.reference <- subcorpora |> filter(name == "2019") |> pull(id)
```

### Creation
```{r}
kw.id <- request(str_interp("${url_api}/keyword/")) |> 
  req_body_json(list(corpus_id = corpus.id,
                     subcorpus_id = subcorpus.id,
                     corpus_id_reference = corpus.id.reference,
                     subcorpus_id_reference = subcorpus.id.reference,
                     p = 'lemma',
                     p_reference = 'lemma')) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("id")
```

### Keyword Table
```{r}
kw.items <- request(str_interp("${url_api}/keyword/${kw.id}/items")) |>
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()
  
kw.items |> 
  magrittr::extract2("items") |> 
  magrittr::extract2("scores") |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = kw.items |> magrittr::extract2("items") |> magrittr::extract2("item"))
```

## Example: SZ-2020 vs. remainder of SZ-2018-2022

### Creation
```{r}
kw.id <- request(str_interp("${url_api}/keyword/")) |> 
  req_body_json(list(corpus_id = corpus.id,
                     subcorpus_id = subcorpus.id,
                     corpus_id_reference = corpus.id,
                     p = 'lemma',
                     p_reference = 'lemma')) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("id")
```

### Keyword Table
```{r}
kw.items <- request(str_interp("${url_api}/keyword/${kw.id}/items")) |>
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("items")
  
kw.items$scores |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = kw.items$item)
```

### Concordance Lines

- clicking on an item in the keyword table (or the semantic map, see below) should retrieve concordance lines featuring this item
- we retrieve concordance lines using the assisted query endpoint (`/query/assisted/`), see below for more details
- note that we performed the keyword analysis on the `p="lemma"` layer

```{r}
query <- request(str_interp("${url_api}/query/assisted")) |> 
  req_body_json(list(p = "lemma", items = list("Corona-Bonds"), corpus_id = corpus.id)) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

query.id <- query |> magrittr::extract2("id")
```

- access to concordance lines via `/query/<id>/concordance`
```{r}
concordance.lines <- request(str_interp("${url_api}/query/${query.id}/concordance")) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("lines")
```

- actual concordance lines can be found in `tokens`
```{r}
concordance.lines |> magrittr::extract2("tokens") |> head(2)
```

- meta data are stored in `structural`
```{r}
concordance.lines |> magrittr::extract2("structural")
```

- when working on a subcorpus, the query must be defined on this subcorpus
- here: `"SZ-2020"`
```{r}
query <- request(str_interp("${url_api}/query/assisted")) |> 
  req_body_json(list(p = "lemma", items = list("Corona-Bonds"), corpus_id = corpus.id, subcorpus_id = subcorpus.id, s = "text")) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

query.id <- query |> magrittr::extract2("id")
```

```{r}
request(str_interp("${url_api}/query/${query.id}/concordance")) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("lines") |> 
  magrittr::extract2("structural") |> pull(text_date)
```

- see below for more details on concordancing

### Visualisation (Semantic Map)

- keyword tables (and collocation tables, see below) are visualised via semantic maps
- association measures and (initial) coordinates are provided by the backend
- semantic maps should display the top `page_size=200` items according to the `sort_by="conservative_log_ratio"` association measure
  + user should be able to set these parameters
  + we set `page_size=50` here, frontend should make the map zoomable (best case: get more items until a user-defined cut-off)

#### Creation of semantic maps

semantic maps are created by default for all keyword and collocation analyses:

    GET /query/<query_id>/collocation/
    POST /keyword/

you can de-activate this behaviour setting `semantic_map_init=False`.

this makes sure that all top items of the analysis actually have coordinates on the provided semantic map (if any).  if `semantic_map_id=None`, this creates a new semantic map.

a combined semantic map based on items of several analyses can be created using

    PUT /semantic-map/
    
coordinates can then be accessed via

    GET /semantic-map/<id>/coordinates/

note that all items have to sets of coordinates: the initial coordinates that are automatically created and user-defined coordinates (which are all `None` after directly after creation).

modifying the user coordinates works via

    PUT /semantic-map/<id>/coordinates/
    
"deleting" user coordinates means setting them to `None`.


#### Coordinates in keyword analyses

- coordinates are provided automatically for all items
```{r}
kw.table.page <- request(str_interp("${url_api}/keyword/${kw.id}/items")) |>
  req_url_query(sort_by = "conservative_log_ratio", page_size = 50, page_number = 1) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

coordinates <- kw.table.page |>
  magrittr::extract2("coordinates") |> 
  tibble()

coordinates
```

- note that two types of coordinates are given:
  + initial coordinates as determined by the backend
  + user coordinates that take precedence if defined via dragging on the semantic map by the user
- semantic map = two-dimensional arrangement using coordinates + size = association measure

```{r}
scores <- kw.table.page |>
  magrittr::extract2("items") |> 
  magrittr::extract2("scores") |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = kw.table.page |> magrittr::extract2("items") |> magrittr::extract2("item"))

map <- scores |> 
  left_join(coordinates, by = "item") |> 
  mutate(x = if_else(!is.na(x_user), x_user, x),
         y = if_else(!is.na(y_user), y_user, y)) |> 
  select(item, conservative_log_ratio, x, y)

map |> 
  filter(conservative_log_ratio > 0) |>
  ggplot(aes(x = x, y = y, label = item)) + 
  geom_label_repel(aes(size = conservative_log_ratio), max.overlaps = Inf, point.size = NA, min.segment.length = Inf) +
  xlab("") + ylab("") +
  theme(legend.position = "bottom")
```

- we filter out all items with `conservative_log_ratio <= 0` here, which is probably reasonable
  - at the very least, items with `E11 >= O11` should not be displayed
  - no defaults implemented!
    + some reasonable defaults can be proposed though
    + best case scenario: user-defined

#### Interaction

- clicking on an item should retrieve relevant concordance lines, see above

- dragging an item updates its user coordinates
```{r}
semantic_map.id <- coordinates |> pull(semantic_map_id) |> head(1)

coordinates <- request(str_interp("${url_api}/semantic-map/${semantic_map.id}/coordinates/")) |>
  req_method('put') |> 
  req_body_json(list(item = "Corona-Bonds", x_user = 35, y_user = 20)) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

map <- scores |> 
  left_join(coordinates, by = "item") |> 
  mutate(x = if_else(!is.na(x_user), x_user, x),
         y = if_else(!is.na(y_user), y_user, y)) |> 
  select(item, conservative_log_ratio, x, y)

map |> 
  filter(conservative_log_ratio > 0) |>
  ggplot(aes(x = x, y = y, label = item)) + 
  geom_label_repel(aes(size = conservative_log_ratio), max.overlaps = Inf, point.size = NA, min.segment.length = Inf) +
  xlab("") + ylab("") +
  theme(legend.position = "bottom")
```

- dropping two items together will create a discourseme, see separate document

# Query

## Creation

- we create a query using the full query end point here
  - for assisted mode, see above
  - for creating queries from discoursemes, see separate document

```{r}
query <- str_interp("${url_api}/query/") |> 
  request() |> 
  req_body_json(list(corpus_id = corpus.id, cqp_query = '[lemma="Klimawandel"%cd] | [lemma="global"] [lemma="Erwärmung"]')) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> magrittr::extract2("body") |> rawToChar() |> fromJSON()

query.id <- query |> magrittr::extract2("id")
```

## Concordancing

```{r}
concordance.lines <- request(str_interp("${url_api}/query/${query.id}/concordance")) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("lines")
```

```{r}
concordance.lines |> names()

concordance.lines |> 
  magrittr::extract2("tokens") |> 
  head(1)
```

### Filtering

- we can filter concordance lines according to certain items in the context (`out_of_window=FALSE`)

```{r}
item = "Erderwärmung"

concordance.lines <- request(str_interp("${url_api}/query/${query.id}/concordance")) |> 
  req_url_query(filter_item = item, filter_item_p_att = 'lemma') |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("lines")
```

```{r}
concordance.lines |> 
  magrittr::extract2("tokens") |> head(1)
```

### Sorting

- we can sort according to certain offsets
- note that this only works with sort_order != 'random'
```{r}
concordance.lines <- request(str_interp("${url_api}/query/${query.id}/concordance")) |> 
  req_url_query(sort_by_offset = 1, sort_by_p_att = 'lemma', sort_order = 'ascending', page_size = 20, page_number = 150) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("lines")
```

```{r}
for (i in 1:20){
  concordance.lines  |> 
    magrittr::extract2("tokens") |> magrittr::extract2(i) |> 
    tibble() |> 
    filter(offset == 1) |> 
    pull(secondary) |> 
    print()
}
```


## Breakdown

- breakdown of the query shows which items were found (and their absolute and relative frequency (instances per million (ipm) in the corpus))
```{r}
breakdown <- request(str_interp("${url_api}/query/${query.id}/breakdown")) |> 
  req_auth_bearer_token(access.token) |>
  req_url_query(p = "lemma") |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("items") |> 
  tibble()
```

```{r}
breakdown|> select(item, ipm, freq, nr_tokens)
```

- note that nr_tokens (and ipm) is correctly calculated in subcorpora
```{r}
subcorpus.query.id <- str_interp("${url_api}/query/") |> 
  request() |> 
  req_body_json(list(corpus_id = corpus.id, subcorpus_id = subcorpus.id, cqp_query = '[lemma="Klimawandel"%cd] | [lemma="global"] [lemma="Erwärmung"]')) |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> magrittr::extract2("body") |> rawToChar() |> fromJSON() |>
  magrittr::extract2("id")

request(str_interp("${url_api}/query/${subcorpus.query.id}/breakdown")) |> 
  req_auth_bearer_token(access.token) |>
  req_url_query(p = "lemma") |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("items") |> 
  tibble() |> 
  select(item, ipm, freq, nr_tokens)
```

## Meta Distribution

- meta data must be stored in database for this to work (see above)
- meta distribution via annotated (`key`) s-attribute (`level`) with p-attribute breakdown (`p`)
```{r}
query.meta <- request(str_interp("${url_api}/query/${query.id}/meta")) |> 
    req_auth_bearer_token(access.token) |>
    req_url_query(level = "text", key = "year", p = "lemma") |> 
    req_perform() |> 
    magrittr::extract2("body") |> rawToChar() |> fromJSON()

query.meta
```

- distribution across categorical meta data can be visualised using barplots
```{r}
query.meta |> mutate(year = lubridate::floor_date(as.Date(value, "y%Y"), "year")) |> 
  ggplot(aes(x = year, y = ipm, fill = item)) +
  geom_col()
```

- visualisation is only reasonable for categorical data
- other visualisations possible but not implemented

- again, if you try to do this without storing the meta data first, you'll get a `404`
```{r, error = TRUE}
query.meta <- request(str_interp("${url_api}/query/${query.id}/meta")) |> 
    req_auth_bearer_token(access.token) |>
    req_url_query(level = "text", key = "month", p = "lemma") |> 
    req_perform() |> 
    magrittr::extract2("body") |> rawToChar() |> fromJSON()
```

## Collocation

### Creation

- collocation analyses are linked to queries (words that appear in the vicinity of the query matches)

```{r}
collocation <- request(str_interp("${url_api}/query/${query.id}/collocation")) |> 
  req_auth_bearer_token(access.token) |>
  req_url_query(p = "lemma") |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON()

collocation.id <- collocation |> magrittr::extract2("id")
```

### Collocation Table

- cf. keyword table
```{r}
coll.table.page <- request(str_interp("${url_api}/collocation/${collocation.id}/items")) |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() 

coll.table.page |> 
  magrittr::extract2("items") |> 
  magrittr::extract2("scores") |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = coll.table.page |> magrittr::extract2("items") |> magrittr::extract2("item"))
```

### Semantic Map

- cf. semantic map in keyword analyses
```{r}
coll.table.page <- request(str_interp("${url_api}/collocation/${collocation.id}/items")) |> 
  req_url_query(page_size = 50) |> 
  req_auth_bearer_token(access.token) |>
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() 

scores <- coll.table.page |> 
  magrittr::extract2("items") |> 
  magrittr::extract2("scores") |> 
  bind_rows(.id = "item") |>
  pivot_wider(names_from = measure, values_from = score) |> 
  mutate(item = coll.table.page |> magrittr::extract2("items") |> magrittr::extract2("item"))

coordinates <- coll.table.page |>
  magrittr::extract2("coordinates") |> 
  tibble()

map <- scores |> 
  left_join(coordinates, by = "item") |> 
  mutate(x = if_else(!is.na(x_user), x_user, x),
         y = if_else(!is.na(y_user), y_user, y)) |> 
  select(item, conservative_log_ratio, x, y)

map |> 
  filter(conservative_log_ratio > 0) |>
  ggplot(aes(x = x, y = y, label = item)) + 
  geom_label_repel(aes(size = conservative_log_ratio), max.overlaps = Inf, point.size = NA, min.segment.length = Inf) +
  xlab("") + ylab("") +
  theme(legend.position = "bottom")
```

### Concordancing

- note that when clicking on an item here, concordance lines have to be filtered according to initial query _and_ the additional filter item
- you can use the additonal filter item as an argument at `/query/<id>/concordance`
```{r}
item = "Artensterben"

concordance.lines <- request(str_interp("${url_api}/query/${query.id}/concordance")) |> 
  req_url_query(filter_item = item, filter_item_p_att = 'lemma') |> 
  req_auth_bearer_token(access.token) |> 
  req_perform() |> 
  magrittr::extract2("body") |> rawToChar() |> fromJSON() |> 
  magrittr::extract2("lines")

concordance.lines |> 
  magrittr::extract2("tokens") |> head(1)
```
